# 产品边界与功能范围

## 一、产品定位

**一句话描述**：面向 AI 开发团队的提示词测试与模型评估平台

**目标用户**：
- AI 应用开发者
- 提示词工程师
- QA 测试工程师

**核心价值**：
- 提示词变更可追溯、可回滚
- 批量测试自动化执行
- 评估方式灵活可编程
- 性能监控持续运行

---

## 二、功能边界

### 2.1 明确要做的功能

| 模块 | 功能项 | MVP | V2 | V3 |
|------|--------|-----|-----|-----|
| **提示词管理** | 创建/编辑/删除提示词 | ✅ | | |
| | 版本历史记录 | ✅ | | |
| | 版本 Diff 对比 | ✅ | | |
| | 版本回滚 | ✅ | | |
| | 变量插槽 `{{var}}` | ✅ | | |
| | 分支管理（实验分支） | | ✅ | |
| | 版本效果对比分析 | | | ✅ |
| **数据集管理** | 上传 xlsx/csv | ✅ | | |
| | 模板下载 | ✅ | | |
| | 数据预览（分页） | ✅ | | |
| | 在线编辑单条 | ✅ | | |
| | 持久化存储选项 | ✅ | | |
| | 数据集版本管理 | | ✅ | |
| **模型配置** | 添加模型提供商 | ✅ | | |
| | 配置 API Key/Endpoint | ✅ | | |
| | 连通性测试 | ✅ | | |
| | 默认参数配置 | ✅ | | |
| | 费率配置（成本计算） | | ✅ | |
| | 多模型对比分析 | | | ✅ |
| **评估器** | 预置评估器（5种） | ✅ | | |
| | 代码评估器（Node.js） | ✅ | | |
| | 代码评估器（Python） | | ✅ | |
| | LLM-as-Judge | | ✅ | |
| | 组合评估器 | | ✅ | |
| | 智能评估器推荐 | | | ✅ |
| **测试执行** | 单任务执行 | ✅ | | |
| | 批量并发执行 | ✅ | | |
| | 执行进度实时推送 | ✅ | | |
| | 失败重试 | ✅ | | |
| | 任务终止 | ✅ | | |
| | A/B 对比测试 | | ✅ | |
| | 断点续跑 | | ✅ | |
| | 任务配置模板 | | | ✅ |
| **结果分析** | 结果列表查看 | ✅ | | |
| | 通过/失败筛选 | ✅ | | |
| | 导出 xlsx/csv | ✅ | | |
| | 统计概览（通过率、耗时） | ✅ | | |
| | 导出 JSON | | ✅ | |
| | 智能分析引擎 | | | ✅ |
| | 失败模式聚类 | | | ✅ |
| | 优化建议生成 | | | ✅ |
| **定时监控** | 创建定时任务 | | ✅ | |
| | Cron 表达式配置 | | ✅ | |
| | 执行历史 | | ✅ | |
| | 性能趋势图表 | | ✅ | |
| | 回归测试追踪 | | | ✅ |
| **告警** | 告警规则配置 | | ✅ | |
| | 阈值触发 | | ✅ | |
| | 邮件/Webhook 通知 | | ✅ | |
| | 智能异常检测 | | | ✅ |
| **项目管理** | 多项目隔离 | | ✅ | |
| | 成员管理 | | ✅ | |
| | 角色权限 | | ✅ | |
| **系统** | 用户登录 | ✅ | | |
| | 操作日志 | | ✅ | |
| | API Token | | ✅ | |
| **用户体验** | 全局搜索命令面板 | | | ✅ |
| | 快捷键系统 | | | ✅ |
| | 新用户引导向导 | | | ✅ |
| | 上下文感知提示 | | | ✅ |
| **UI/UX 优化** | 工作台重构（统计卡片、趋势图表） | | ✅ | |
| | 任务列表卡片化展示 | | ✅ | |
| | 提示词批量操作与快速预览 | | ✅ | |
| | 数据集上传流程优化 | | ✅ | |
| | 模型配置分组与连接状态可视化 | | ✅ | |
| | 评估器展示增强 | | ✅ | |
| | 监控中心数据可视化 | | ✅ | |
| | 设置页面分组卡片化 | | ✅ | |

### 2.2 明确不做的功能

| 功能 | 不做的理由 |
|------|-----------|
| 模型训练/微调 | 超出产品定位，属于 MLOps 范畴 |
| 提示词自动优化 | 复杂度高，可作为远期目标 |
| 实时对话测试 | 本产品专注批量评估，非交互式 |
| 向量知识库 | 属于 RAG 应用构建，非测试平台职责 |
| 移动端 App | 优先 Web 端，移动端需求不强 |
| 多语言 UI | MVP 仅支持中文 |
| 私有化部署配置界面 | 通过环境变量配置 |
| 用户注册（开放注册） | MVP 仅支持管理员创建账号 |

---

## 三、核心概念定义

### 3.1 实体关系

```
用户(User)
  └── 项目(Project) [V2]
        ├── 提示词(Prompt) ──► 版本(PromptVersion)
        ├── 数据集(Dataset) ──► 数据行(DatasetRow)
        ├── 模型配置(Model)
        ├── 评估器(Evaluator)
        └── 测试任务(Task) ──► 测试结果(TaskResult) ──► 评估结果(EvaluationResult)
```

### 3.2 术语表

| 术语 | 英文 | 定义 |
|------|------|------|
| 提示词 | Prompt | 发送给 LLM 的文本模板，可包含变量插槽 |
| 版本 | Version | 提示词的一次快照，不可修改 |
| 数据集 | Dataset | 测试用例集合，包含输入和期望输出 |
| 数据行 | DatasetRow | 数据集中的单条测试用例 |
| 评估器 | Evaluator | 判断模型输出是否符合预期的规则或代码 |
| 预置评估器 | Preset Evaluator | 系统内置的评估规则（精确匹配等） |
| 代码评估器 | Code Evaluator | 用户自定义的评估代码 |
| 测试任务 | Task | 一次测试执行，包含配置和状态 |
| 测试结果 | TaskResult | 单条测试用例的执行结果 |
| 评估结果 | EvaluationResult | 评估器对单条结果的判定 |

### 3.3 变量插槽规则

提示词中使用 `{{变量名}}` 格式定义变量：

```
你是一个{{role}}助手。

用户问题：{{question}}

请用{{language}}回答。
```

**变量来源**：数据集中的字段自动映射

**保留变量**：
- `{{input}}` - 如果数据集只有一个输入字段，自动映射
- `{{expected}}` - 期望输出字段（用于评估）

---

## 四、用户故事

### 4.1 提示词工程师

```
作为提示词工程师，我希望：
- 能够安全地修改提示词并保存为新版本
- 在发布前用测试数据集验证效果
- 如果新版本效果不好，可以快速回滚
- 对比不同版本的提示词效果差异
```

### 4.2 QA 测试工程师

```
作为 QA 测试工程师，我希望：
- 上传测试用例集（xlsx格式）
- 配置自定义的评估规则（代码）
- 一键运行批量测试
- 导出测试报告
```

### 4.3 AI 应用开发者

```
作为 AI 应用开发者，我希望：
- 配置多个模型 API 进行对比测试
- 设置定时任务监控模型性能
- 当模型响应异常时收到告警
- 追踪 API 调用的 Token 消耗和成本
```

---

## 五、非功能需求

### 5.1 性能要求

| 指标 | 目标值 |
|------|--------|
| 页面首屏加载 | < 2s |
| API 响应时间（非 LLM） | < 200ms |
| 单任务最大数据量 | 10,000 条 |
| 并发任务数 | 10 个 |
| 单任务最大并发请求 | 20 个 |

### 5.2 数据要求

| 项目 | 要求 |
|------|------|
| 数据集单文件大小 | ≤ 50MB |
| 单条数据字段数 | ≤ 50 个 |
| 提示词长度 | ≤ 100,000 字符 |
| 测试结果保留时间 | 永久（可手动删除） |

### 5.3 安全要求

| 项目 | 要求 |
|------|------|
| API Key 存储 | 加密存储，界面脱敏显示 |
| 代码沙箱 | 隔离执行，限制资源和网络 |
| 用户认证 | Session + Token 双模式 |
| 敏感操作 | 记录审计日志 |
