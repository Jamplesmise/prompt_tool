# GOI 智能水平递进规划

## 文档背景

当前状态：L2 级别功能已完成
目标：通过细粒度里程碑划分，逐步提升AI智能水平，每个阶段聚焦解决一类问题

---

## 当前状态

### L2 级别已完成 (2025-12)

L2 能力清单：

| 能力 | 状态 | 说明 |
|------|------|------|
| 多步骤计划生成 | ✅ 已完成 | Planner + LLM 自动拆解任务为 TODO List |
| 操作可视化 | ✅ 已完成 | VisualExecutor 实时显示执行过程 |
| 检查点确认 | ✅ 已完成 | CheckpointManager 关键决策点暂停确认 |
| 暂停与接管 | ✅ 已完成 | PauseController + ControlTransfer 支持人机切换 |
| 人工操作感知 | ✅ 已完成 | ActionTracker + PlanReconciler 识别用户操作 |
| 断点续跑 | ✅ 已完成 | 从正确位置继续执行 |
| 偏离检测 | ✅ 已完成 | DeviationDetector 检测计划偏离 |

### 代码位置

```
apps/web/src/lib/goi/
├── agent/
│   ├── planner.ts          # 计划生成器
│   ├── planReconciler.ts   # 计划协调器
│   └── agentLoop.ts        # Agent 主循环
├── collaboration/
│   ├── actionTracker.ts    # 操作追踪器
│   ├── deviationDetector.ts # 偏离检测器
│   └── controlTransfer.ts  # 控制权转移
├── execution/
│   ├── visualExecutor.ts   # 可视化执行器
│   ├── pauseController.ts  # 暂停控制器
│   └── progressSync.ts     # 进度同步
└── checkpoint/
    └── manager.ts          # 检查点管理器
```

### 测试覆盖

- 单元测试: `apps/web/src/lib/goi/__tests__/`
  - planner.test.ts
  - actionTracker.test.ts
  - planReconciler.test.ts
  - deviationDetector.test.ts
- E2E 测试: `apps/web/e2e/goi/`
  - l2-validation.spec.ts (L2 专项验证)

---

## 智能水平分级模型

我们将AI智能水平划分为 **L0-L5** 六个等级，每个等级代表一种能力层次：

| 等级 | 能力描述 | 类比 |
|------|---------|------|
| L0 | 能执行明确指令 | 命令行工具 |
| L1 | 能理解模糊意图 | 搜索引擎 |
| L2 | 能规划多步任务 | 导航软件 |
| L3 | 能感知执行状态 | 自动驾驶L2 |
| L4 | 能处理异常情况 | 自动驾驶L3 |
| L5 | 能自主决策优化 | 自动驾驶L4 |

**当前评估**：系统大约处于 L1-L2 之间，能理解意图、能生成计划，但执行监控和异常处理较弱。

---

## 细粒度里程碑规划

### 第一阶段：夯实基础（L1完善）

#### M1.1 意图理解准确率提升
**当前问题**：
- AI有时误解用户意图，生成错误的任务计划
- 对专业术语理解不准确
- 多个意图混在一起时解析混乱

**达标标准**：
- 单一明确意图识别准确率 > 95%
- 识别出意图中的关键实体（prompt名称、数据集名称、模型名称等）准确率 > 90%
- 当意图模糊时，AI主动追问而不是猜测执行
- 当检测到多个意图时，AI列出并请用户确认优先级

**验收场景**：
```
用户输入: "用那个情感分析的prompt测一下"
期望AI响应: "我理解你想创建测试任务。请确认：
- 使用的prompt：检测到2个包含'情感分析'的prompt
  1. sentiment-analysis-v1 (情感二分类)
  2. sentiment-analysis-v2 (情感多分类)
  请问使用哪一个？
- 数据集：未指定，需要你选择"
```

**关键改进点**：
- 实体识别增强：对平台内资源名称做模糊匹配
- 意图置信度：低于阈值时触发澄清对话
- 多意图拆分：识别"并且"、"然后"等连接词

---

#### M1.2 计划展示清晰度提升
**当前问题**：
- TODO列表太技术化，用户看不懂
- 步骤之间的关系不清晰
- 用户不知道每步要做什么、为什么做

**达标标准**：
- 每个TODO项用用户能理解的自然语言描述
- 展示步骤分组（准备阶段/执行阶段/验证阶段）
- 关键步骤标注说明（为什么需要这步）
- 预估总耗时和当前进度百分比

**改进前 vs 改进后**：
```
改进前：
☐ navigate /tasks/new
☐ click #prompt-selector
☐ input "sentiment" 
☐ select first result
☐ click #dataset-selector
...

改进后：
📋 创建测试任务 (预计3分钟)

▸ 准备工作 [2步]
  ☐ 打开任务创建页面
  ☐ 选择Prompt → sentiment-analysis-v2
    💡 这是你指定的情感分析prompt
  
▸ 配置数据 [2步]  
  ☐ 选择数据集 → (待你确认)
  ☐ 配置字段映射
    💡 需要把数据集的列对应到prompt的变量
    
▸ 执行验证 [2步]
  ☐ 启动测试任务
  ☐ 等待完成并生成报告
```

---

#### M1.3 基础交互响应优化
**当前问题**：
- AI响应慢，用户等待焦虑
- 不知道AI在干什么（加载中无反馈）
- 长任务没有进度感

**达标标准**：
- 用户输入后 500ms 内有响应（至少显示"正在理解..."）
- 生成计划时显示思考过程（"正在分析你的需求..." → "正在规划步骤..."）
- 超过3秒的操作显示进度指示
- 每完成一个TODO项立即更新状态

**体验改进**：
- 打字机效果展示AI思考
- 步骤完成时的微动画反馈
- 预计剩余时间动态更新

---

### 第二阶段：执行可控（L2-L3）

#### M2.1 操作可视化
**当前问题**：
- AI执行时用户不知道发生了什么
- 界面变化但不知道是AI做的还是系统自动的
- 执行太快，用户跟不上

**达标标准**：
- AI每执行一个操作，对应的UI元素有视觉高亮
- 显示操作说明气泡（"正在点击这个按钮"）
- 可调节执行速度（快速/正常/慢速演示）
- 操作历史可回看

**视觉反馈设计**：
```
当AI点击某个按钮时：
1. 按钮周围出现呼吸光圈（0.3秒）
2. 旁边浮现说明："AI正在选择这个prompt"
3. 点击动画
4. TODO列表对应项打勾
```

---

#### M2.2 检查点确认机制
**当前问题**：
- AI一路执行没有确认点，用户失去控制感
- 关键决策AI自己做了，用户不知道
- 想中途改主意很困难

**达标标准**：
- 定义清晰的检查点规则（什么操作需要确认）
- 检查点暂停时展示决策信息供用户判断
- 提供"确认/修改/跳过"三个选项
- 用户可自定义检查点敏感度

**默认检查点触发条件**：
- 选择关键资源（prompt、数据集、模型）
- 执行不可逆操作（删除、提交、发布）
- 涉及费用（调用付费API）
- 任务首次执行（学习用户偏好）

**确认对话框设计**：
```
┌─────────────────────────────────────────┐
│ ⏸️ AI暂停确认                           │
├─────────────────────────────────────────┤
│ 即将执行：选择数据集                      │
│                                         │
│ AI的选择：test-dataset-v2               │
│ 选择原因：名称最匹配你说的"测试数据集"      │
│                                         │
│ 其他候选：                               │
│  · test-dataset-v1 (较旧版本)           │
│  · test-dataset-dev (开发环境)          │
│                                         │
│ [✓ 确认] [✎ 换一个] [⏭ 跳过此步]        │
└─────────────────────────────────────────┘
```

---

#### M2.3 随时暂停与接管
**当前问题**：
- 用户想中途停下来AI不响应
- 暂停后不知道当前状态
- 接管后AI不知道用户做了什么

**达标标准**：
- 任意时刻点击暂停，AI在当前原子操作完成后立即停止
- 暂停时清晰显示：已完成什么、正在做什么、还剩什么
- 用户手动操作时AI静默观察
- 接管后AI能识别用户做了哪些步骤

**状态展示**：
```
⏸️ 已暂停

已完成 (3/8)：
  ✓ 打开任务创建页
  ✓ 选择Prompt
  ✓ 选择数据集
  
暂停在：
  ◉ 配置字段映射 ← 执行到这里暂停了
  
等待执行 (4项)：
  ○ 选择评估模型
  ○ 设置评估指标
  ○ 启动任务
  ○ 生成报告

[▶ 继续执行] [✋ 我来操作] [✕ 取消任务]
```

---

#### M2.4 人工操作感知
**当前问题**：
- 用户手动做了某些步骤，AI不知道
- AI继续执行时重复用户已完成的操作
- 用户改了AI的选择，AI没有更新计划

**达标标准**：
- 用户在界面上的操作被实时捕获
- AI判断用户操作对应TODO列表的哪一步
- 自动更新TODO状态（跳过已完成步骤）
- 用户修改AI选择时更新后续依赖

**感知场景**：
```
[AI暂停中，用户接管操作]

用户手动选择了数据集: customer-feedback-jan

AI感知并更新：
"检测到你选择了数据集 customer-feedback-jan
 ✓ 已将步骤'选择数据集'标记为完成
 ⚠️ 注意：此数据集的字段与之前不同，步骤'字段映射'需要重新规划"
```

---

### 第三阶段：异常处理（L4）

#### M3.1 错误识别与分类
**当前问题**：
- 出错只显示技术错误信息，用户看不懂
- 不区分错误类型，处理方式一刀切
- 用户不知道为什么出错

**达标标准**：
- 错误信息翻译成用户能理解的语言
- 区分临时错误（可重试）和永久错误（需干预）
- 给出可能的原因分析
- 建议下一步行动

**错误分类与响应**：

| 错误类型 | 识别特征 | 用户提示 | 建议行动 |
|---------|---------|---------|---------|
| 网络超时 | timeout, network | "网络连接暂时不稳定" | 自动重试 |
| 资源不存在 | 404, not found | "找不到xxx" | 检查名称或选其他 |
| 权限不足 | 403, unauthorized | "你没有xxx权限" | 联系管理员 |
| 数据格式错误 | validation, format | "数据格式不对" | 检查输入 |
| 服务繁忙 | 429, rate limit | "服务暂时繁忙" | 稍后重试 |
| 系统内部错误 | 500, internal | "系统出了点问题" | 报告问题 |

**错误提示示例**：
```
❌ 步骤失败：选择数据集

发生了什么：
  找不到名为 "test-dataset-v2" 的数据集

可能原因：
  · 数据集名称拼写有误
  · 数据集已被删除或重命名
  · 你没有该数据集的访问权限

建议操作：
  [🔍 搜索相似数据集] [✎ 手动输入] [⏭ 跳过] [✕ 取消]
```

---

#### M3.2 智能重试机制
**当前问题**：
- 临时错误不会重试，直接失败
- 重试没有策略，可能加重问题
- 重试过程用户无感知

**达标标准**：
- 临时错误自动重试（最多3次）
- 重试使用退避策略（间隔递增）
- 重试过程有进度展示
- 重试失败后才提示用户

**重试策略**：
```
第1次重试：立即
第2次重试：等待2秒
第3次重试：等待5秒
仍失败：提示用户介入

界面显示：
"网络超时，正在重试... (2/3)"
[████████░░] 等待2秒后重试
```

---

#### M3.3 操作回滚能力
**当前问题**：
- 执行失败后系统处于中间状态
- 用户不知道哪些已生效、哪些没有
- 手动恢复很困难

**达标标准**：
- 记录每个操作前的状态快照
- 失败时自动回滚到上一个稳定状态
- 回滚操作清晰可见
- 回滚后状态与操作前一致

**回滚机制设计**：
```
快照时机：
  · 任务开始前（完整快照）
  · 每个检查点确认后（增量快照）
  · 关键资源变更前（变更快照）

回滚粒度选择：
  · 回滚单步：撤销当前失败的操作
  · 回滚到检查点：撤销到上次确认
  · 回滚整个任务：恢复到任务开始前

回滚展示：
"正在回滚操作...
 ↩️ 删除刚创建的任务草稿 (ID: task-123)
 ↩️ 恢复数据集选择器状态
 ✓ 已回滚到步骤2完成后的状态"
```

---

#### M3.4 失败后选项处理
**当前问题**：
- 失败后只能取消重来
- 没有灵活的处理选项
- 用户的选择AI不能理解

**达标标准**：
- 提供多种失败处理选项
- 每个选项解释清楚后果
- 用户选择后AI正确响应
- 支持用户自定义处理方式

**失败处理选项**：
```
❌ 执行失败

[重试] 用相同参数再试一次
       适合：临时性错误（网络、超时）

[换个方式] 让AI尝试其他方法
          适合：当前方法受阻但有替代方案

[跳过此步] 标记为跳过，继续后续步骤  
          适合：此步骤非必需
          ⚠️ 可能影响后续步骤

[我来处理] 暂停AI，我手动完成这步
          适合：需要人工判断

[取消任务] 回滚所有操作，结束任务
          适合：不想继续了
```

---

### 第四阶段：上下文智能（L4-L5）

#### M4.1 长对话记忆保持
**当前问题**：
- 对话长了AI忘记前面说的
- 重复问同样的问题
- 之前的决策没有被记住

**达标标准**：
- 关键信息始终保持（用户偏好、已确认的决策）
- 对话超过阈值时自动压缩
- 压缩不丢失重要信息
- 用户可以问"我们之前决定了什么"

**记忆分层**：
```
永久保持（不压缩）：
  · 用户明确表达的偏好（"我喜欢用GPT-4"）
  · 已确认的关键决策
  · 任务目标和约束条件

优先保持（后压缩）：
  · 最近3轮对话详情
  · 当前任务上下文
  · 失败原因和解决方案

可压缩（优先丢弃）：
  · 执行细节日志
  · 中间状态数据
  · 已完成步骤的详情
```

---

#### M4.2 上下文容量管理
**当前问题**：
- 上下文满了突然失效
- 用户不知道上下文使用情况
- 压缩时机不可预期

**达标标准**：
- 显示上下文使用量指示器
- 接近上限时提前预警
- 支持用户主动触发压缩
- 压缩后告知保留了什么

**容量管理界面**：
```
上下文容量：[████████░░] 78%

接近上限时提示：
"💡 对话较长，建议整理一下：
 [自动整理] 保留关键信息，压缩细节
 [继续对话] 先不整理，快满时再说"

压缩后反馈：
"✓ 已整理对话，释放了40%空间
 保留的关键信息：
 · 任务目标：创建测试任务
 · 已选prompt：sentiment-v2  
 · 你的偏好：优先使用GPT-4模型"
```

---

#### M4.3 跨任务经验学习
**当前问题**：
- 每次任务都从零开始
- 不记得用户习惯
- 重复问相同的配置问题

**达标标准**：
- 记住用户常用的资源（prompt、数据集、模型）
- 学习用户的操作习惯
- 新任务时提供智能默认值
- 可以关闭学习功能（隐私）

**学习内容**：
```
用户偏好档案：
  常用Prompt: sentiment-v2, summary-v1
  常用数据集: production-samples
  偏好模型: GPT-4 > Claude > 其他
  确认偏好: 关键步骤确认
  执行速度: 正常
  
智能建议：
"检测到你上次也用了 sentiment-v2 和 production-samples，
 这次要使用相同配置吗？[是] [否，我要改]"
```

---

#### M4.4 主动建议能力
**当前问题**：
- AI只被动响应，不会主动帮助
- 有更好的方式AI不会说
- 用户走弯路AI不提醒

**达标标准**：
- 发现潜在问题主动提醒
- 有更优方案时建议替代
- 预测用户下一步可能需要什么
- 建议非强制，用户可忽略

**主动建议场景**：
```
场景1 - 发现问题：
"💡 注意：你选择的数据集有35%的空值，
 可能影响测试结果。建议先清洗数据或换一个数据集。"

场景2 - 更优方案：
"💡 建议：你选择了逐条执行，但数据量较大(1000条)，
 批量执行可以快10倍，要切换吗？"

场景3 - 预测需求：
"✓ 测试任务已完成
 💡 通常下一步你可能想：
 [查看详细报告] [导出结果] [创建类似任务] [优化Prompt]"
```

---

### 第五阶段：生产就绪（L5）

#### M5.1 性能优化
**达标标准**：
- 意图理解响应 < 1秒
- 计划生成 < 3秒
- 单步执行 < 2秒
- UI同步延迟 < 200ms

**优化方向**：
- 请求合并与缓存
- 流式响应
- 预加载常用数据
- 后台预处理

---

#### M5.2 稳定性保障
**达标标准**：
- 任务成功率 > 90%
- 回滚成功率 > 99%
- 无数据丢失
- 降级方案可用（AI不可用时不影响传统模式）

---

#### M5.3 可观测性
**达标标准**：
- 完整的操作日志
- AI决策可追溯
- 错误统计与分析
- 用户行为分析

---

#### M5.4 用户引导
**达标标准**：
- 新用户引导流程
- 功能发现提示
- 帮助文档集成
- 反馈收集机制

---

## 里程碑依赖关系

```
M1.1 意图理解 ─┬─→ M1.2 计划展示 ─→ M1.3 响应优化
               │
               ↓
M2.1 操作可视化 ─→ M2.2 检查点确认 ─┬─→ M2.3 暂停接管
                                    │
                                    ↓
                   M2.4 操作感知 ←──┘
                        │
                        ↓
M3.1 错误识别 ─→ M3.2 智能重试 ─→ M3.3 操作回滚 ─→ M3.4 失败处理
                                        │
                                        ↓
M4.1 记忆保持 ─→ M4.2 容量管理 ─→ M4.3 经验学习 ─→ M4.4 主动建议
                                                         │
                                                         ↓
                    M5.1 性能 ─→ M5.2 稳定性 ─→ M5.3 可观测 ─→ M5.4 引导
```

---

## 推荐实施顺序

考虑到价值和依赖关系，建议按以下顺序实施：

**第一优先级（快速见效）**：
1. M1.1 意图理解准确率 - 解决最基础的问题
2. M1.2 计划展示清晰度 - 提升用户信任感
3. M2.2 检查点确认 - 给用户控制感

**第二优先级（核心体验）**：
4. M2.1 操作可视化 - 知道AI在干什么
5. M2.3 暂停与接管 - 人机切换
6. M3.1 错误识别分类 - 出错能看懂

**第三优先级（可靠性）**：
7. M3.2 智能重试 - 减少用户干预
8. M3.3 操作回滚 - 失败能恢复
9. M3.4 失败处理选项 - 灵活应对

**第四优先级（智能化）**：
10. M2.4 人工操作感知 - 双向感知
11. M4.1 记忆保持 - 长对话
12. M4.3 经验学习 - 越用越懂你

**第五优先级（上线准备）**：
13. M1.3 响应优化
14. M4.2 容量管理
15. M4.4 主动建议
16. M5.x 生产就绪

---

## 评估检查清单

每个里程碑完成后，用以下问题验收：

**功能完整性**：
- [ ] 所有达标标准都有对应功能实现
- [ ] 验收场景可以复现
- [ ] 边界情况已处理

**用户体验**：
- [ ] 新用户3分钟内能理解怎么用
- [ ] 操作反馈及时清晰
- [ ] 错误提示用户能看懂

**稳定性**：
- [ ] 连续操作10次无异常
- [ ] 弱网环境下不崩溃
- [ ] 异常情况有兜底

---

## 附录：当前问题清单（待填充）

在实施过程中，持续收集和分类问题：

| 问题描述 | 归属里程碑 | 优先级 | 状态 |
|---------|-----------|-------|------|
| AI理解错用户意图 | M1.1 | P0 | 待解决 |
| TODO列表太技术化 | M1.2 | P1 | 待解决 |
| ... | ... | ... | ... |

---

*文档版本：v1.0*  
*最后更新：2024年*
